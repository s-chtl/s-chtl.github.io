<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2 | Academic</title>
    <link>https://example.com/publication-type/2/</link>
      <atom:link href="https://example.com/publication-type/2/index.xml" rel="self" type="application/rss+xml" />
    <description>2</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>2</title>
      <link>https://example.com/publication-type/2/</link>
    </image>
    
    <item>
      <title>SoK: Privacy-Preserving Collaborative Tree-based Model Learning</title>
      <link>https://example.com/publication/sok/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/sok/</guid>
      <description>&lt;p&gt;Tree-based models are among the most efficient machine learning techniques for data mining nowadays due to their accuracy, interpretability, and simplicity. The recent orthogonal needs for more data and privacy protection call for collaborative privacy-preserving solutions. In this work, we survey the literature on distributed and privacy-preserving training of tree-based models and we systematize its knowledge based on four axes: the learning algorithm, the collaborative model, the protection mechanism, and the threat model. We use this to identify the strengths and limitations of these works and provide for the first time a framework analyzing the information leakage occurring in distributed tree-based model learning.&lt;/p&gt;
&lt;p&gt;The latest version of this work is available on &lt;a href=&#34;https://arxiv.org/abs/2103.08987&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ArXiv&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decentralized Privacy-Preserving Proximity Tracing</title>
      <link>https://example.com/publication/dp3t/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/dp3t/</guid>
      <description>&lt;p&gt;This document describes and analyzes a system for secure and privacy-preserving proximity tracing at large scale. This system, referred to as DP3T, provides a technological foundation to help slow the spread of SARS-CoV-2 by simplifying and accelerating the process of notifying people who might have been exposed to the virus so that they can take appropriate measures to break its transmission chain. The system aims to minimise privacy and security risks for individuals and communities and guarantee the highest level of data protection. The goal of our proximity tracing system is to determine who has been in close physical proximity to a COVID-19 positive person and thus exposed to the virus, without revealing the contact&amp;rsquo;s identity or where the contact occurred. To achieve this goal, users run a smartphone app that continually broadcasts an ephemeral, pseudo-random ID representing the user&amp;rsquo;s phone and also records the pseudo-random IDs observed from smartphones in close proximity. When a patient is diagnosed with COVID-19, she can upload pseudo-random IDs previously broadcast from her phone to a central server. Prior to the upload, all data remains exclusively on the user&amp;rsquo;s phone. Other users&amp;rsquo; apps can use data from the server to locally estimate whether the device&amp;rsquo;s owner was exposed to the virus through close-range physical proximity to a COVID-19 positive person who has uploaded their data. In case the app detects a high risk, it will inform the user.&lt;/p&gt;
&lt;p&gt;The latest version of this work is available on &lt;a href=&#34;https://arxiv.org/abs/2005.12273&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ArXiv&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducing Meta-learning with differentiable closed-form solvers</title>
      <link>https://example.com/publication/reproducibility/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/reproducibility/</guid>
      <description>&lt;p&gt;In this paper, we present a reproduction of the paper of Bertinetto et al.[2019] &amp;lsquo;Meta-learning with differentiable closed-form solvers&amp;rsquo; as part of the ICLR 2019 Reproducibility Challenge. In successfully reproducing the most crucial part of the paper, we reach a performance that is comparable with or superior to the original paper on two benchmarks for several settings. We evaluate new baseline results, using a new dataset presented in the paper. Yet, we also provide multiple remarks and recommendations about reproducibility and comparability. After we brought our reproducibility work to the authorsâ€™ attention, they have updated the original paper on which this work is based and released code as well. Our contributions mainly consist in reproducing the most important results of their original paper, in giving insight in the reproducibility and in providing a first open-source implementation.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
